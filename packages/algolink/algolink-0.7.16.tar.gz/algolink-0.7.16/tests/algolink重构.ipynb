{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function roc_auc_score at 0x7fd493019320> roc_auc_score\n",
      "{'train': <algolink.core.objects.core.EvaluationSet object at 0x7fd4959e3dd0>}\n",
      "{'train_input': <algolink.core.objects.dataset_source.InMemoryDatasetSource object at 0x7fd495a199d0>,\n",
      " 'train_output': <algolink.core.objects.dataset_source.InMemoryDatasetSource object at 0x7fd4959e3a90>}\n",
      "{'auc': <algolink.core.objects.metric.LibFunctionMetric object at 0x7fd4957cd9d0>,\n",
      " 'custom': <algolink.core.objects.metric.CallableMetric object at 0x7fd49599ec50>}\n",
      "{'predict': ('__call__',\n",
      "             <class 'pyjackson.generics.DataFrameType[columns=['a', 'b'],dtypes=['int64', 'int64'],index_cols=[]]'>,\n",
      "             <class 'pyjackson.generics.NumpyNdarrayDatasetType[shape=(2,),dtype=int64]'>)}\n",
      "{'predict': ('__call__',\n",
      "             <class 'pyjackson.generics.DataFrameType[columns=['a', 'b'],dtypes=['int64', 'int64'],index_cols=[]]'>,\n",
      "             <class 'pyjackson.generics.NumpyNdarrayDatasetType[shape=(2,),dtype=int64]'>)}\n",
      "{'constant': EvaluationResult(timestamp=1633322044.205685,scores={'auc': 0.5, 'custom': 0.0}), 'truth': EvaluationResult(timestamp=1633322044.205685,scores={'auc': 1.0, 'custom': 100.0})}\n",
      "{'author': 'leepand',\n",
      " 'creation_date': '2021-10-04 04:34:04.084864 ',\n",
      " 'datasets': {'train_input': {'artifacts': {'blobs': {'data.pd': {'path': '/Users/leepand/Downloads/MLOps/AlgoLink/tests/.algolink/artifacts/datasets/0/train_input/data.pd',\n",
      "                                                                  'type': 'local_file'}},\n",
      "                                            'type': 'blobs'},\n",
      "                              'dataset_type': {'columns': ['a', 'b'],\n",
      "                                               'dtypes': ['int64', 'int64'],\n",
      "                                               'index_cols': [],\n",
      "                                               'type': 'algolink.ext.pandas.dataset.DataFrameType'},\n",
      "                              'reader': {'data_type': {'columns': ['a', 'b'],\n",
      "                                                       'dtypes': ['int64',\n",
      "                                                                  'int64'],\n",
      "                                                       'index_cols': [],\n",
      "                                                       'type': 'algolink.ext.pandas.dataset.DataFrameType'},\n",
      "                                         'format': {'read_args': {},\n",
      "                                                    'type': 'csv',\n",
      "                                                    'write_args': {}},\n",
      "                                         'type': 'algolink.ext.pandas.dataset_source.PandasReader'},\n",
      "                              'type': 'algolink.repository.dataset.artifact.ArtifactDatasetSource'},\n",
      "              'train_output': {'artifacts': {'blobs': {'data.npz': {'path': '/Users/leepand/Downloads/MLOps/AlgoLink/tests/.algolink/artifacts/datasets/0/train_output/data.npz',\n",
      "                                                                    'type': 'local_file'}},\n",
      "                                             'type': 'blobs'},\n",
      "                               'dataset_type': {'dtype': 'int64',\n",
      "                                                'shape': [None],\n",
      "                                                'type': 'algolink.ext.numpy.dataset.NumpyNdarrayDatasetType'},\n",
      "                               'reader': {'type': 'algolink.ext.numpy.dataset_source.NumpyNdarrayReader'},\n",
      "                               'type': 'algolink.repository.dataset.artifact.ArtifactDatasetSource'}},\n",
      " 'evaluation_sets': {'train': {'input_dataset': 'train_input',\n",
      "                               'metrics': ['auc', 'custom'],\n",
      "                               'output_dataset': 'train_output'}},\n",
      " 'id': 0,\n",
      " 'metrics': {'auc': {'args': {},\n",
      "                     'function': 'sklearn.metrics._ranking.roc_auc_score',\n",
      "                     'invert_input': False,\n",
      "                     'type': 'algolink.core.objects.metric.LibFunctionMetric'},\n",
      "             'custom': {'type': 'algolink.core.objects.metric.CallableMetric',\n",
      "                        'wrapper': {'artifacts': {'model.pkl': 'eJxVijFPg1AUhS+gbUWrVVmMg2s70KipshhjwuBAwoAOz+kFH8+UBHgceAwkbeLS/g79p7528ybnO/nuvd+OyPKimPMdXS4amWrJv7pK6FxVLmj6716oNOO6r6ULi42IKFSZfDcOewMnwcE0siMycaIw9FbWD/3Sina8pszy6I1wGL++fNB+thgwx3TblRhuMGIDIz3XTSdxxIZ7aYVqJNwtjtmNWTzlda+XqvLzqu60v3jwg1sRBI+pCD7v755xwibmq+y56FqtSl5K3eQC4+gqtMnC6WymcZZgssb5chzHa1zEGpcJvPkf4gRKSQ=='},\n",
      "                                    'requirements': {'requirements': []}}}},\n",
      " 'name': 'regression_is_my_profession',\n",
      " 'project_id': 0}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyjackson import serialize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import algolink\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    data = pd.DataFrame([[1, 0], [0, 1]], columns=['a', 'b'])\n",
    "    target = np.array([1, 0])\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def constant(data):\n",
    "    return np.array([0 for _ in range(len(data))])\n",
    "\n",
    "\n",
    "def truth(data: pd.DataFrame):\n",
    "    return np.array([r[0] for _, r in data.iterrows()])\n",
    "\n",
    "\n",
    "def my_custom_metric(y_true, y_score):\n",
    "    return y_score.sum() / y_true.sum() * 100.\n",
    "\n",
    "\n",
    "def main():\n",
    "    ebnt = algolink.AlgoLink.local(clear=True)\n",
    "\n",
    "    data, target = get_data()\n",
    "    # we want easy way to transform anything to datasets, so its either this or ebonite.create_dataset (same for metrics)\n",
    "    # for now there is no difference, however if we want manage datasets with meta and art repos, we use client\n",
    "    # or create with ebonite.create_... and then push with ebnt.push_... like for models\n",
    "    # dataset = ebnt.create_dataset(data, target)\n",
    "\n",
    "    # here we postpone setting task input and output types for easy task creation\n",
    "    task = ebnt.get_or_create_task('my_project', 'regression_is_my_profession')\n",
    "    print(roc_auc_score,\"roc_auc_score\")\n",
    "    task.add_metric('auc', roc_auc_score)\n",
    "    task.add_metric('custom', my_custom_metric)\n",
    "    task.add_evaluation('train', data, target, ['auc', 'custom'])\n",
    "\n",
    "    pprint(task.evaluation_sets)\n",
    "    pprint(task.datasets)\n",
    "    pprint(task.metrics)\n",
    "\n",
    "    # omit providing dataset as we already have it in task\n",
    "    mc = task.create_and_push_model(constant, data, model_name='constant')\n",
    "    mt = task.create_and_push_model(truth, data, model_name='truth')\n",
    "\n",
    "    pprint(mc.wrapper.methods)\n",
    "    pprint(mt.wrapper.methods)\n",
    "\n",
    "    # maybe save result to models? also need different ways to evaluate \"not all\"\n",
    "    result = task.evaluate_all()\n",
    "\n",
    "    print(result)\n",
    "    ebnt._bind(task)\n",
    "    task.save()\n",
    "    pprint(serialize(task))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_task_churn_model\n",
      "{'train': <algolink.core.objects.core.EvaluationSet object at 0x7ff5dfd544d0>}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyjackson import serialize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import algolink\n",
    "from algolink import AlgoLink\n",
    "\n",
    "def get_data():\n",
    "    data = pd.DataFrame([[1, 0], [0, 1]], columns=['a', 'b'])\n",
    "    target = np.array([1, 0])\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def constant(data):\n",
    "    return np.array([0 for _ in range(len(data))])\n",
    "\n",
    "\n",
    "def truth(data: pd.DataFrame):\n",
    "    return np.array([r[0] for _, r in data.iterrows()])\n",
    "\n",
    "\n",
    "def my_custom_metric(y_true, y_score):\n",
    "    return y_score.sum() / y_true.sum() * 100.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_one(data):\n",
    "    return data + 1\n",
    "\n",
    "from algolink.core.objects.dataset_source import Dataset\n",
    "from algolink.repository import DatasetRepository\n",
    "\n",
    "\n",
    "def test_save(dataset_repo: DatasetRepository, data: Dataset):\n",
    "    source = dataset_repo.save('a', data)\n",
    "    data2 = source.read()\n",
    "\n",
    "ebnt = AlgoLink.local(\"./dataset\")\n",
    "data, target = get_data()\n",
    "task3 = ebnt.get_or_create_task('my_project', 'my_task2')\n",
    "dataset = ebnt.create_dataset(data, target)\n",
    "task3.save()\n",
    "#task3.add_metric('auc', roc_auc_score)\n",
    "    \n",
    "#task3.add_metric('custom', my_custom_metric)\n",
    "#task3.add_evaluation('train', data, target, ['auc', 'custom'])\n",
    "#task3.save()\n",
    "#ebnt.create_metric(1)\n",
    "def main():\n",
    "    #  create remote ebonite client. This client stores metadata in postgres/sqlite and artifacts in s3\n",
    "    alink = AlgoLink.custom_client('sqlalchemy', 'local',\n",
    "                                 meta_kwargs={'db_uri': 'sqlite:///sql.db'},\n",
    "                                 artifact_kwargs={'path': './'})\n",
    "    # save client configuration for later use\n",
    "    alink.save_client_config('client_config.json')\n",
    "    \n",
    "    #  obtain Task\n",
    "    task = alink.get_or_create_task('my_project', 'my_task_churn_model')\n",
    "    print(task.name)\n",
    "    #  remove model if it exists (for demo purposes)\n",
    "    if task.models.contains('add_one_model'):\n",
    "        model = task.models('add_one_model')\n",
    "        task.delete_model(model)\n",
    "\n",
    "    task.add_metric('auc', roc_auc_score)\n",
    "    \n",
    "    task.add_metric('custom', my_custom_metric)\n",
    "    task.add_evaluation('train', data, target, ['auc', 'custom'])\n",
    "    pprint(task.evaluation_sets)\n",
    "    #task.evaluate_all()\n",
    "    #  create model from function add_one and numpy array as data sample\n",
    "    model = algolink.create_model(add_one, np.array([0]), 'churn_model')\n",
    "    #model.evaluate_set('test_bool', method_name='predict1', raise_on_error=True)\n",
    "    #  persist model\n",
    "    task.push_model(model)\n",
    "    task.push_datasets()\n",
    "    model.artifact_any\n",
    "    model.artifact_req_persisted\n",
    "    #model.evaluate_set(['d'],\"sd\",\"roc\")\n",
    "    alink._bind(task)\n",
    "    task.save()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m.\u001b[m\u001b[m                    algolink重构.ipynb   model_tracking.py\n",
      "\u001b[34m..\u001b[m\u001b[m                   client_config.json   sql.db\n",
      "\u001b[34m.algolink\u001b[m\u001b[m            \u001b[34mdatasets\u001b[m\u001b[m             test.py\n",
      "\u001b[34m.ipynb_checkpoints\u001b[m\u001b[m   \u001b[34mmodel\u001b[m\u001b[m                tests.ipynb\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m          model-track.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/leepand/Downloads/MLOps/AlgoLink/tests\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algolink重构.ipynb   \u001b[34mmodel\u001b[m\u001b[m                test.py\n",
      "client_config.json   sql.db               tests.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebonite.repository import DatasetRepository\n",
    "DatasetRepository().save('a', \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m.\u001b[m\u001b[m            \u001b[34m..\u001b[m\u001b[m           \u001b[34mtrain_input\u001b[m\u001b[m  \u001b[34mtrain_output\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -a .algolink/artifacts/datasets/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf .algolink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task(id=0,name=my_task2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpo_50\n",
      "{'train': <algolink.core.objects.core.EvaluationSet object at 0x7fe12bc63fd0>}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyjackson import serialize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import algolink\n",
    "from algolink import AlgoLink\n",
    "\n",
    "def get_data():\n",
    "    data = pd.DataFrame([[1, 0], [0, 1]], columns=['a', 'b'])\n",
    "    target = np.array([1, 0])\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def constant(data):\n",
    "    return np.array([0 for _ in range(len(data))])\n",
    "\n",
    "\n",
    "def truth(data: pd.DataFrame):\n",
    "    return np.array([r[0] for _, r in data.iterrows()])\n",
    "\n",
    "\n",
    "def my_custom_metric(y_true, y_score):\n",
    "    return y_score.sum() / y_true.sum() * 100.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_one(data):\n",
    "    return data + 1\n",
    "\n",
    "from algolink.core.objects.dataset_source import Dataset\n",
    "from algolink.repository import DatasetRepository\n",
    "\n",
    "\n",
    "def test_save(dataset_repo: DatasetRepository, data: Dataset):\n",
    "    source = dataset_repo.save('a', data)\n",
    "    data2 = source.read()\n",
    "\n",
    "#ebnt = AlgoLink.local(\"./dataset\")\n",
    "#data, target = get_data()\n",
    "#task3 = ebnt.get_or_create_task('my_project', 'my_task2')\n",
    "#dataset = ebnt.create_dataset(data, target)\n",
    "#task3.save()\n",
    "#task3.add_metric('auc', roc_auc_score)\n",
    "    \n",
    "#task3.add_metric('custom', my_custom_metric)\n",
    "#task3.add_evaluation('train', data, target, ['auc', 'custom'])\n",
    "#task3.save()\n",
    "#ebnt.create_metric(1)\n",
    "def main():\n",
    "    #  create remote ebonite client. This client stores metadata in postgres/sqlite and artifacts in s3\n",
    "    alink = AlgoLink.custom_client('sqlalchemy', 'local',\n",
    "                                 meta_kwargs={'db_uri': 'sqlite:///sql.db'},\n",
    "                                 artifact_kwargs={'path': './'})\n",
    "    # save client configuration for later use\n",
    "    alink.save_client_config('client_config.json')\n",
    "    \n",
    "    #  obtain Task\n",
    "    task = alink.get_or_create_task('mlops_19', 'lpo_50')\n",
    "    print(task.name)\n",
    "    #  remove model if it exists (for demo purposes)\n",
    "    if task.models.contains('churn_model8'):\n",
    "        model = task.models('churn_model8')\n",
    "        task.delete_model(model)\n",
    "\n",
    "    task.add_metric('auc', roc_auc_score)\n",
    "    \n",
    "    task.add_metric('custom', my_custom_metric)\n",
    "    task.add_evaluation('train', data, target, ['auc', 'custom'])\n",
    "    pprint(task.evaluation_sets)\n",
    "    #task.evaluate_all()\n",
    "    #  create model from function add_one and numpy array as data sample\n",
    "    model = algolink.create_model(add_one, np.array([0]), 'churn_model8')\n",
    "    #model.evaluate_set('test_bool', method_name='predict1', raise_on_error=True)\n",
    "    #  persist model\n",
    "    task.push_model(model)\n",
    "    #task.push_datasets()\n",
    "    #model.artifact_any\n",
    "    #model.artifact_req_persisted\n",
    "    #model.evaluate_set(['d'],\"sd\",\"roc\")\n",
    "    #alink._bind(task)\n",
    "    #task.save()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[distutils]\n",
    "index-servers=pypi\n",
    "\n",
    "[pypi]\n",
    "repository = https://upload.pypi.org/legacy/\n",
    "username = <pandasasa>\n",
    "password = <lipd@123>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
