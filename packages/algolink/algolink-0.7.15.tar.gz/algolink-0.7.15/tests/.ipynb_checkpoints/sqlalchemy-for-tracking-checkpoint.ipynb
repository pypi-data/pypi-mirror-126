{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] epoch_list\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'conn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-c58e4d41331b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0mtable_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodify_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_table_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtable_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_model_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_model_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m \u001b[0mgenerate_loss_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_model_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-c58e4d41331b>\u001b[0m in \u001b[0;36mgenerate_loss_data\u001b[0;34m(MetaRepo, task_id, sub_model_result)\u001b[0m\n\u001b[1;32m    113\u001b[0m           \u001b[0;34m\"left join tasks m on m.id = sm.task_id \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m           \u001b[0;34m\"where m.id=%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mmax_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mx_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_step\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conn' is not defined"
     ]
    }
   ],
   "source": [
    "from algolink.ext.sqlalchemy.repository import SQLAlchemyMetaRepository\n",
    "from algolink.ext.sqlalchemy.models import Attaching,TExperiment,STask,TModelparam,TBestresult\n",
    "\n",
    "test = SQLAlchemyMetaRepository(\"sqlite:///sql.db\")\n",
    "\n",
    "# 构造表头\n",
    "def generate_table_head(MetaRepo,task_id):\n",
    "    experiment_model_result = MetaRepo._get_objects(TExperiment,TExperiment.task_id==task_id)\n",
    "    \n",
    "    # 构造表头\n",
    "    table_head = {}\n",
    "    table_length = {}\n",
    "    sub_model_param = {}\n",
    "    \n",
    "    for sub_model in experiment_model_result:\n",
    "        \n",
    "        model_param_result = MetaRepo._get_objects(TModelparam, TModelparam.experiment_id==sub_model.id)\n",
    "        for model_param in model_param_result:\n",
    "            if model_param.param_type not in table_head:\n",
    "                table_head[model_param.param_type] = [model_param.name]\n",
    "            else:\n",
    "                if model_param.name not in table_head[model_param.param_type]:\n",
    "                    table_head[model_param.param_type].append(model_param.name)\n",
    "            # sub_model_param\n",
    "            if sub_model.id not in sub_model_param:\n",
    "                sub_model_param[sub_model.id] = {model_param.name: model_param.param_value}\n",
    "            else:\n",
    "                sub_model_param[sub_model.id][model_param.name] = model_param.param_value\n",
    "    for type, param_list in table_head.items():\n",
    "        table_length[type] = len(param_list)\n",
    "\n",
    "    return experiment_model_result, sub_model_param, table_head, table_length\n",
    "\n",
    "# 构造页面数据 sub_model_result = experiment_model_result\n",
    "def generate_table_data(MetaRepo, table_head, sub_model_result, sub_model_param):\n",
    "    table_data = []\n",
    "    best_head = []\n",
    "    best_data = {}\n",
    "    first_param = {}\n",
    "    modify_head = []\n",
    "    id = 0\n",
    "    for i, sub_model in enumerate(sub_model_result):\n",
    "\n",
    "        # 评估指标数据\n",
    "        best_result = MetaRepo._get_objects(TBestresult,TBestresult.experiment_id==sub_model.id)\n",
    "        dic = {}\n",
    "\n",
    "        flag = False\n",
    "        for best in best_result:\n",
    "            if best.name not in best_head:\n",
    "                best_head.append(best.name)\n",
    "\n",
    "            dic[best.name] = best.best_value\n",
    "            flag = True\n",
    "\n",
    "        best_data[sub_model.id] = dic\n",
    "\n",
    "        id += 1\n",
    "        dic = {}\n",
    "\n",
    "        dic['id'] = id\n",
    "        dic['sub_model_id'] = sub_model.id\n",
    "        dic['sub_model_name'] = sub_model.name\n",
    "        dic['sub_model_remark'] = sub_model.experiment_remark\n",
    "        dic['create_time'] = sub_model.creation_date\n",
    "\n",
    "        if flag:\n",
    "            dic['finished_train'] = True\n",
    "        else:\n",
    "            dic['finished_train'] = False\n",
    "\n",
    "        # 超参数\n",
    "        for _, param_list in table_head.items():\n",
    "            for param_name in param_list:\n",
    "\n",
    "                try:\n",
    "                    dic[param_name] = sub_model_param[sub_model.id][param_name]\n",
    "                except:\n",
    "                    dic[param_name] = ''\n",
    "\n",
    "                if i == 0:  # 记录第一次训练的超参数\n",
    "                    first_param[param_name] = dic[param_name]\n",
    "                else:\n",
    "                    if dic[param_name] != first_param[param_name]:\n",
    "                        modify_head.append(param_name)\n",
    "\n",
    "        # 评估指标数据\n",
    "        for name in best_head:\n",
    "            try:\n",
    "                dic[name] = best_data[sub_model.id][name]\n",
    "            except:\n",
    "                dic[name] = ''\n",
    "\n",
    "        table_data.append(dic)\n",
    "\n",
    "\n",
    "    return table_data, best_head, modify_head\n",
    "\n",
    "# 构造loss画图数据\n",
    "def generate_loss_data(MetaRepo, task_id, sub_model_result):\n",
    "    exp_list = MetaRepo._get_objects(TExperiment,TExperiment.task_id == task_id)\n",
    "    epoch_list = []\n",
    "    for exp in exp_list:\n",
    "        _epoch_class_list = MetaRepo._get_objects(TModelmetric,TModelmetric.experiment_id == exp.id)\n",
    "        for _epoch_class in _epoch_class_list:\n",
    "            epoch_list.append(_epoch_class.epoch)\n",
    "            \n",
    "    max_step = max(epoch_list)\n",
    "    x_value = [i for i in range(1, max_step + 1)]\n",
    "\n",
    "    legend = {}\n",
    "    series = []\n",
    "    for i, sub_model in enumerate(sub_model_result):\n",
    "\n",
    "        if i + 1 == len(sub_model_result):\n",
    "            legend[sub_model.name + '_train'] = 'true'\n",
    "            legend[sub_model.name + '_test'] = 'true'\n",
    "        else:\n",
    "            legend[sub_model.name + '_train'] = 'false'\n",
    "            legend[sub_model.name + '_test'] = 'false'\n",
    "\n",
    "        _train_value = \n",
    "        sql = \"select md.metric_value from model_metrics md where md.experiment_id=%d and md.name='train_loss'\" % (\n",
    "        sub_model[0])\n",
    "        train_value = [value[0] for value in conn.execute(sql)]\n",
    "        data_dic = {'name': sub_model[1] + '_train', 'data': str(train_value)}\n",
    "        series.append(data_dic)\n",
    "\n",
    "        sql = \"select md.metric_value from model_metrics md where md.experiment_id=%d and md.name='test_loss'\" % (\n",
    "        sub_model[0])\n",
    "        test_value = [value[0] for value in conn.execute(sql)]\n",
    "        data_dic = {'name': sub_model[1] + '_test', 'data': str(test_value)}\n",
    "        series.append(data_dic)\n",
    "\n",
    "    x_value = str(x_value)\n",
    "\n",
    "    return legend, x_value, series\n",
    "\n",
    "sub_model_result, sub_model_param, table_head, table_length = generate_table_head(test,2)\n",
    "\n",
    "table_data, best_head, modify_head = generate_table_data(test, table_head, sub_model_result, sub_model_param)\n",
    "\n",
    "generate_loss_data(test, 2, sub_model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'id': 1,\n",
       "   'sub_model_id': 2,\n",
       "   'sub_model_name': 'test_track6',\n",
       "   'sub_model_remark': 'experiment_remark',\n",
       "   'create_time': datetime.datetime(2021, 10, 16, 8, 28, 50, 595045),\n",
       "   'finished_train': True,\n",
       "   'model': 'BILSTM_Attention',\n",
       "   'optimizer': 'adam',\n",
       "   'num_classes': '10',\n",
       "   'lr': '0.001',\n",
       "   'training_steps': '1000000',\n",
       "   'display_step': '1',\n",
       "   'batch_size': '100',\n",
       "   'num_hidden': '128',\n",
       "   'embedding_dim': '128',\n",
       "   'drop_out': '0.5',\n",
       "   'best_loss': 2.34},\n",
       "  {'id': 2,\n",
       "   'sub_model_id': 3,\n",
       "   'sub_model_name': 'test_track7',\n",
       "   'sub_model_remark': 'experiment_remark',\n",
       "   'create_time': datetime.datetime(2021, 10, 16, 16, 13, 0, 386830),\n",
       "   'finished_train': False,\n",
       "   'model': '',\n",
       "   'optimizer': '',\n",
       "   'num_classes': '',\n",
       "   'lr': '',\n",
       "   'training_steps': '',\n",
       "   'display_step': '',\n",
       "   'batch_size': '',\n",
       "   'num_hidden': '',\n",
       "   'embedding_dim': '',\n",
       "   'drop_out': '',\n",
       "   'best_loss': ''}],\n",
       " ['best_loss'],\n",
       " ['model',\n",
       "  'optimizer',\n",
       "  'num_classes',\n",
       "  'lr',\n",
       "  'training_steps',\n",
       "  'display_step',\n",
       "  'batch_size',\n",
       "  'num_hidden',\n",
       "  'embedding_dim',\n",
       "  'drop_out'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_data, best_head, modify_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Experiment(id=2,name=test_track6)\n",
      "1 Experiment(id=3,name=test_track7)\n"
     ]
    }
   ],
   "source": [
    "for i, sub_model in enumerate(u[0]):\n",
    "    print(i,sub_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Experiment(id=2,name=test_track6), Experiment(id=3,name=test_track7)]\n",
      "[Experiment(id=2,name=test_track6), Experiment(id=3,name=test_track7)]\n"
     ]
    }
   ],
   "source": [
    "for j in u:\n",
    "    print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Experiment(id=2,name=test_track6), Experiment(id=3,name=test_track7)],\n",
       " {2: {'model': 'BILSTM_Attention',\n",
       "   'optimizer': 'adam',\n",
       "   'num_classes': '10',\n",
       "   'lr': '0.001',\n",
       "   'training_steps': '1000000',\n",
       "   'display_step': '1',\n",
       "   'batch_size': '100',\n",
       "   'num_hidden': '128',\n",
       "   'embedding_dim': '128',\n",
       "   'drop_out': '0.5'}},\n",
       " {'tf_param': ['model',\n",
       "   'optimizer',\n",
       "   'num_classes',\n",
       "   'lr',\n",
       "   'training_steps',\n",
       "   'display_step',\n",
       "   'batch_size',\n",
       "   'num_hidden',\n",
       "   'embedding_dim',\n",
       "   'drop_out']},\n",
       " {'tf_param': 10})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Experiment(id=2,name=test_track6), Experiment(id=3,name=test_track7)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Boolean value of this clause is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-3652b6abc934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTExperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/algolink/ext/sqlalchemy/repository.py\u001b[0m in \u001b[0;36m_get_objects\u001b[0;34m(self, object_type, add_filter)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Getting %ss with filter %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0madd_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sqlalchemy/sql/elements.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3250\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Boolean value of this clause is not defined\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3254\u001b[0m     \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Boolean value of this clause is not defined"
     ]
    }
   ],
   "source": [
    "exp=test._get_objects(TExperiment,add_filter=(TExperiment.id.is_(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'author': 'leepand',\n",
      "  'creation_date': '2021-10-16 07:50:31.206202 ',\n",
      "  'experiment_remark': 'experiment_remark',\n",
      "  'experiment_sequence': 1,\n",
      "  'id': 1,\n",
      "  'name': 'test_track5',\n",
      "  'task_id': 1},\n",
      " {'author': 'leepand',\n",
      "  'creation_date': '2021-10-16 08:28:50.595045 ',\n",
      "  'experiment_remark': 'experiment_remark',\n",
      "  'experiment_sequence': 1,\n",
      "  'id': 2,\n",
      "  'name': 'test_track6',\n",
      "  'task_id': 2},\n",
      " {'author': 'leepand',\n",
      "  'creation_date': '2021-10-16 16:13:00.386830 ',\n",
      "  'experiment_remark': 'experiment_remark',\n",
      "  'experiment_sequence': 2,\n",
      "  'id': 3,\n",
      "  'name': 'test_track7',\n",
      "  'task_id': 2}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from pyjackson import serialize\n",
    "\n",
    "pprint(serialize(exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1), (1)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contextlib\n",
    "from algolink.repository.metadata import MetadataRepository\n",
    "from typing import List, Optional, Type, TypeVar, Union\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from sqlalchemy.orm import Session, sessionmaker\n",
    "from algolink.ext.sqlalchemy.models import (Attaching, Base,TModelmetric,TExperiment,STask)\n",
    "from algolink.utils.log import logger\n",
    "\n",
    "\n",
    "class SQLAlchemyMetaRepository(object):\n",
    "    \"\"\"\n",
    "    :class:`.MetadataRepository` implementation which stores metadata in SQL database via `sqlalchemy` library.\n",
    "\n",
    "    :param db_uri: URI of SQL database to connect to\n",
    "    \"\"\"\n",
    "\n",
    "    type = 'sqlalchemy'\n",
    "\n",
    "\n",
    "    def __init__(self, db_uri: str):\n",
    "        self.db_uri = db_uri\n",
    "        self._engine = create_engine(db_uri)\n",
    "        Base.metadata.create_all(self._engine)\n",
    "        self._Session = sessionmaker(bind=self._engine)\n",
    "        self._active_session = None\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _session(self) -> Session:\n",
    "        if self._active_session is None:\n",
    "            logger.debug('Creating session for %s', self.db_uri)\n",
    "            self._active_session = self._Session()\n",
    "            new_session = True\n",
    "        else:\n",
    "            new_session = False\n",
    "\n",
    "        try:\n",
    "            yield self._active_session\n",
    "\n",
    "            if new_session:\n",
    "                self._active_session.commit()\n",
    "        except:  # noqa\n",
    "            if new_session:\n",
    "                self._active_session.rollback()\n",
    "            raise\n",
    "        finally:\n",
    "            if new_session:\n",
    "                self._active_session.close()\n",
    "                self._active_session = None\n",
    "\n",
    "    def _get_objects(self, object_type: Type[Attaching], add_filter=None) -> List:\n",
    "        with self._session() as s:\n",
    "            if add_filter is None:\n",
    "                logger.debug('Getting %ss', object_type.__name__)\n",
    "            else:\n",
    "                logger.debug('Getting %ss with filter %s', object_type.__name__, add_filter)\n",
    "            #.filter(add_filter)\n",
    "            \n",
    "            if add_filter:\n",
    "                print(add_filter)\n",
    "                q = s.query(object_type).filter(TExperiment.task_id==1)\n",
    "            else:\n",
    "                print(\"add_filter\",add_filter)\n",
    "                q = s.query(object_type)\n",
    "            return q#[o.to_obj() for o in q.all()]\n",
    "    def _get_objects_leftjoin(self):\n",
    "        with self._session() as s:\n",
    "            q=s.query(TModelmetric.epoch).outerjoin(TExperiment,TExperiment.id==TModelmetric.experiment_id).\\\n",
    "            outerjoin(STask,STask.id==TExperiment.task_id).all()\n",
    "            return q#[o for o in q.all()]\n",
    "        \n",
    "gg = SQLAlchemyMetaRepository(\"sqlite:///sql.db\")\n",
    "gg._get_objects_leftjoin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT model_metrics.epoch AS model_metrics_epoch \n",
      "FROM model_metrics LEFT OUTER JOIN experiments ON experiments.id = model_metrics.experiment_id LEFT OUTER JOIN tasks ON tasks.id = experiments.task_id\n"
     ]
    }
   ],
   "source": [
    "print(str(gg._get_objects_leftjoin()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_filter experiments.task_id = :task_id_1\n",
      "SELECT experiments.id AS experiments_id, experiments.name AS experiments_name, experiments.author AS experiments_author, experiments.experiment_remark AS experiments_experiment_remark, experiments.experiment_sequence AS experiments_experiment_sequence, experiments.del_flag AS experiments_del_flag, experiments.creation_date AS experiments_creation_date, experiments.task_id AS experiments_task_id \n",
      "FROM experiments\n"
     ]
    }
   ],
   "source": [
    "query=gg._get_objects(TExperiment,TExperiment.task_id==1)\n",
    "print (str(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT experiments.id AS experiments_id, experiments.name AS experiments_name, experiments.author AS experiments_author, experiments.experiment_remark AS experiments_experiment_remark, experiments.experiment_sequence AS experiments_experiment_sequence, experiments.del_flag AS experiments_del_flag, experiments.creation_date AS experiments_creation_date, experiments.task_id AS experiments_task_id \n",
      "FROM experiments\n"
     ]
    }
   ],
   "source": [
    "print (str(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x7fd0bf90bd50>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([(1), (12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
