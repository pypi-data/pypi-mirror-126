{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/MyDrive/nixtlats\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('./drive/MyDrive/nixtlats')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning\n",
    "# !pip install torchinfo\n",
    "# !pip install fastcore\n",
    "# !pip install s3fs\n",
    "# !pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.nbeats.nbeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS: Neural Basis Expansion Analysis\n",
    "\n",
    "> API details.\n",
    "\n",
    "The N-BEATS model decomposes the objective signal by performing separate local nonlinear projections of the target data onto basis functions across its different blocks. Each block of the architecture consists of a multi layer perceptron that learns expansion coefficients for the backcast and forecast elements. The backcast model is used to clean the inputs of subsequent blocks, while the forecasts are summed to compose the final prediction. The blocks are grouped in stacks. Each of the potentially multiple stacks specializes in a different variant of basis functions. Depending on the basis functions the outputs of the model can be interpretable. The [original model](https://github.com/ElementAI/N-BEATS) is implemented in both pytorch and tensorflow.\n",
    "\n",
    "[Oreshkin, B. N., Carpov, D., Chapados, N., & Bengio, Y. (2020). N-BEATS: neural basis expansion analysisfor interpretable time series forecasting.  In 8th  International Conference on Learning Representations, ICLR 2020.](https://openreview.net/forum?id=r1ecqn4YwB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Tuple\n",
    "from functools import partial\n",
    "\n",
    "from nixtlats.models.components.tcn import _TemporalConvNet\n",
    "from nixtlats.models.components.common import Chomp1d, RepeatVector\n",
    "from nixtlats.losses.utils import LossFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _StaticFeaturesEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(_StaticFeaturesEncoder, self).__init__()\n",
    "        layers = [nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features=in_features, out_features=out_features),\n",
    "                  nn.ReLU()]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class _sEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, n_time_in):\n",
    "        super(_sEncoder, self).__init__()\n",
    "        layers = [nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features=in_features, out_features=out_features),\n",
    "                  nn.ReLU()]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        self.repeat = RepeatVector(repeats=n_time_in)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode and repeat values to match time\n",
    "        x = self.encoder(x)\n",
    "        x = self.repeat(x) # [N,S_out] -> [N,S_out,T]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IdentityBasis(nn.Module):\n",
    "    def __init__(self, backcast_size: int, forecast_size: int):\n",
    "        super().__init__()\n",
    "        self.forecast_size = forecast_size\n",
    "        self.backcast_size = backcast_size\n",
    " \n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast = theta[:, :self.backcast_size]\n",
    "        forecast = theta[:, -self.forecast_size:]\n",
    "        return backcast, forecast\n",
    "\n",
    "class TrendBasis(nn.Module):\n",
    "    def __init__(self, degree_of_polynomial: int, backcast_size: int, forecast_size: int):\n",
    "        super().__init__()\n",
    "        polynomial_size = degree_of_polynomial + 1\n",
    "        self.backcast_basis = nn.Parameter(\n",
    "            t.tensor(np.concatenate([np.power(np.arange(backcast_size, dtype=float) / backcast_size, i)[None, :]\n",
    "                                    for i in range(polynomial_size)]), dtype=t.float32), requires_grad=False)\n",
    "        self.forecast_basis = nn.Parameter(\n",
    "            t.tensor(np.concatenate([np.power(np.arange(forecast_size, dtype=float) / forecast_size, i)[None, :]\n",
    "                                    for i in range(polynomial_size)]), dtype=t.float32), requires_grad=False)\n",
    "    \n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        cut_point = self.forecast_basis.shape[0]\n",
    "        backcast = t.einsum('bp,pt->bt', theta[:, cut_point:], self.backcast_basis)\n",
    "        forecast = t.einsum('bp,pt->bt', theta[:, :cut_point], self.forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class SeasonalityBasis(nn.Module):\n",
    "    def __init__(self, harmonics: int, backcast_size: int, forecast_size: int):\n",
    "        super().__init__()\n",
    "        frequency = np.append(np.zeros(1, dtype=float),\n",
    "                                        np.arange(harmonics, harmonics / 2 * forecast_size,\n",
    "                                                    dtype=float) / harmonics)[None, :]\n",
    "        backcast_grid = -2 * np.pi * (\n",
    "                np.arange(backcast_size, dtype=float)[:, None] / forecast_size) * frequency\n",
    "        forecast_grid = 2 * np.pi * (\n",
    "                np.arange(forecast_size, dtype=float)[:, None] / forecast_size) * frequency\n",
    "\n",
    "        backcast_cos_template = t.tensor(np.transpose(np.cos(backcast_grid)), dtype=t.float32)\n",
    "        backcast_sin_template = t.tensor(np.transpose(np.sin(backcast_grid)), dtype=t.float32)\n",
    "        backcast_template = t.cat([backcast_cos_template, backcast_sin_template], dim=0)\n",
    "\n",
    "        forecast_cos_template = t.tensor(np.transpose(np.cos(forecast_grid)), dtype=t.float32)\n",
    "        forecast_sin_template = t.tensor(np.transpose(np.sin(forecast_grid)), dtype=t.float32)\n",
    "        forecast_template = t.cat([forecast_cos_template, forecast_sin_template], dim=0)\n",
    "\n",
    "        self.backcast_basis = nn.Parameter(backcast_template, requires_grad=False)\n",
    "        self.forecast_basis = nn.Parameter(forecast_template, requires_grad=False)\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        cut_point = self.forecast_basis.shape[0]\n",
    "        backcast = t.einsum('bp,pt->bt', theta[:, cut_point:], self.backcast_basis)\n",
    "        forecast = t.einsum('bp,pt->bt', theta[:, :cut_point], self.forecast_basis)\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExogenousBasisInterpretable(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis = insample_x_t\n",
    "        forecast_basis = outsample_x_t\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class ExogenousBasisWavenet(nn.Module):\n",
    "    def __init__(self, out_features, in_features, num_levels=4, kernel_size=3, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        # Shape of (1, in_features, 1) to broadcast over b and t\n",
    "        self.weight = nn.Parameter(t.Tensor(1, in_features, 1), requires_grad=True)\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(0.5))\n",
    "\n",
    "        padding = (kernel_size - 1) * (2**0)\n",
    "        input_layer = [nn.Conv1d(in_channels=in_features, out_channels=out_features,\n",
    "                                 kernel_size=kernel_size, padding=padding, dilation=2**0),\n",
    "                                 Chomp1d(padding),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(dropout_prob)]\n",
    "        conv_layers = []\n",
    "        for i in range(1, num_levels):\n",
    "            dilation = 2**i\n",
    "            padding = (kernel_size - 1) * dilation\n",
    "            conv_layers.append(nn.Conv1d(in_channels=out_features, out_channels=out_features,\n",
    "                                         padding=padding, kernel_size=3, dilation=dilation))\n",
    "            conv_layers.append(Chomp1d(padding))\n",
    "            conv_layers.append(nn.ReLU())\n",
    "        conv_layers = input_layer + conv_layers\n",
    "\n",
    "        self.wavenet = nn.Sequential(*conv_layers)\n",
    "        \n",
    "    def transform(self, insample_x_t, outsample_x_t):\n",
    "        n_time_in = insample_x_t.shape[2]\n",
    "        \n",
    "        x_t = t.cat([insample_x_t, outsample_x_t], dim=2)\n",
    "        \n",
    "        x_t = x_t * self.weight # Element-wise multiplication, broadcasted on b and t. Weights used in L1 regularization\n",
    "        x_t = self.wavenet(x_t)[:]\n",
    "\n",
    "        backcast_basis = x_t[:,:, :n_time_in]\n",
    "        forecast_basis = x_t[:,:, n_time_in:]\n",
    "\n",
    "        return backcast_basis, forecast_basis\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis, forecast_basis = self.transform(insample_x_t, outsample_x_t)\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class ExogenousBasisTCN(nn.Module):\n",
    "    def __init__(self, out_features, in_features, num_levels = 4, kernel_size=2, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        n_channels = num_levels * [out_features]\n",
    "        self.tcn = _TemporalConvNet(num_inputs=in_features, num_channels=n_channels, kernel_size=kernel_size, dropout=dropout_prob)\n",
    "        \n",
    "    def transform(self, insample_x_t, outsample_x_t):\n",
    "        n_time_in = insample_x_t.shape[2]\n",
    "        \n",
    "        x_t = t.cat([insample_x_t, outsample_x_t], dim=2)\n",
    "        \n",
    "        x_t = self.tcn(x_t)[:]\n",
    "        backcast_basis = x_t[:,:, :n_time_in]\n",
    "        forecast_basis = x_t[:,:, n_time_in:]\n",
    "\n",
    "        return backcast_basis, forecast_basis\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis, forecast_basis = self.transform(insample_x_t, outsample_x_t)\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_weights(module, initialization):\n",
    "    if type(module) == t.nn.Linear:\n",
    "        if initialization == 'orthogonal':\n",
    "            t.nn.init.orthogonal_(module.weight)\n",
    "        elif initialization == 'he_uniform':\n",
    "            t.nn.init.kaiming_uniform_(module.weight)\n",
    "        elif initialization == 'he_normal':\n",
    "            t.nn.init.kaiming_normal_(module.weight)\n",
    "        elif initialization == 'glorot_uniform':\n",
    "            t.nn.init.xavier_uniform_(module.weight)\n",
    "        elif initialization == 'glorot_normal':\n",
    "            t.nn.init.xavier_normal_(module.weight)\n",
    "        elif initialization == 'lecun_normal':\n",
    "            pass #t.nn.init.normal_(module.weight, 0.0, std=1/np.sqrt(module.weight.numel()))\n",
    "        else:\n",
    "            assert 1<0, f'Initialization {initialization} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ACTIVATIONS = ['ReLU',\n",
    "               'Softplus',\n",
    "               'Tanh',\n",
    "               'SELU',\n",
    "               'LeakyReLU',\n",
    "               'PReLU',\n",
    "               'Sigmoid']\n",
    "\n",
    "class _NBEATSBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    N-BEATS block which takes a basis function as an argument.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_time_in: int, n_time_out: int, n_x: int,\n",
    "                 n_s: int, n_s_hidden: int, n_theta: int, n_theta_hidden: list,\n",
    "                 basis: nn.Module, \n",
    "                 n_layers: int,  batch_normalization: bool, dropout_prob: float, activation: str):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if n_s == 0:\n",
    "            n_s_hidden = 0\n",
    "        n_theta_hidden = [n_time_in + (n_time_in+n_time_out)*n_x + n_s_hidden] + n_theta_hidden\n",
    "        \n",
    "        self.n_time_in = n_time_in\n",
    "        self.n_time_out = n_time_out\n",
    "        self.n_s = n_s\n",
    "        self.n_s_hidden = n_s_hidden\n",
    "        self.n_x = n_x\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout_prob = dropout_prob\n",
    "        \n",
    "        assert activation in ACTIVATIONS, f'{activation} is not in {ACTIVATIONS}'\n",
    "        activ = getattr(nn, activation)()\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(n_layers):\n",
    "            hidden_layers.append(nn.Linear(in_features=n_theta_hidden[i], out_features=n_theta_hidden[i+1]))\n",
    "            hidden_layers.append(activ)\n",
    "\n",
    "            if self.batch_normalization:\n",
    "                hidden_layers.append(nn.BatchNorm1d(num_features=n_theta_hidden[i+1]))\n",
    "\n",
    "            if self.dropout_prob>0:\n",
    "                hidden_layers.append(nn.Dropout(p=self.dropout_prob))\n",
    "\n",
    "        output_layer = [nn.Linear(in_features=n_theta_hidden[-1], out_features=n_theta)]\n",
    "        layers = hidden_layers + output_layer\n",
    "\n",
    "        # n_s is computed with data, n_s_hidden is provided by user, if 0 no statics are used\n",
    "        if (self.n_s > 0) and (self.n_s_hidden > 0):\n",
    "            self.static_encoder = _StaticFeaturesEncoder(in_features=n_s, out_features=n_s_hidden)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.basis = basis\n",
    "\n",
    "    def forward(self, insample_y: t.Tensor, insample_x_t: t.Tensor,\n",
    "                outsample_x_t: t.Tensor, x_s: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "\n",
    "        batch_size = len(insample_y)\n",
    "        if self.n_x > 0:\n",
    "            insample_y = t.cat(( insample_y, insample_x_t.reshape(batch_size, -1) ), 1)\n",
    "            insample_y = t.cat(( insample_y, outsample_x_t.reshape(batch_size, -1) ), 1)\n",
    "        \n",
    "        # Static exogenous\n",
    "        if (self.n_s > 0) and (self.n_s_hidden > 0):\n",
    "            x_s = self.static_encoder(x_s)\n",
    "            insample_y = t.cat((insample_y, x_s), 1)\n",
    "\n",
    "        # Compute local projection weights and projection\n",
    "        theta = self.layers(insample_y)\n",
    "        backcast, forecast = self.basis(theta, insample_x_t, outsample_x_t)\n",
    "\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _NBEATS(nn.Module):\n",
    "    \"\"\"\n",
    "    N-Beats Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 n_time_in,\n",
    "                 n_time_out,\n",
    "                 n_s,\n",
    "                 n_x,\n",
    "                 n_s_hidden,\n",
    "                 n_x_hidden,\n",
    "                 n_polynomials,\n",
    "                 n_harmonics,\n",
    "                 stack_types: list,\n",
    "                 n_blocks: list,\n",
    "                 n_layers: list,\n",
    "                 n_theta_hidden: list,\n",
    "                 dropout_prob_theta,\n",
    "                 activation,\n",
    "                 initialization,\n",
    "                 batch_normalization,\n",
    "                 shared_weights):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_time_out = n_time_out\n",
    "\n",
    "        blocks = self.create_stack(stack_types=stack_types, \n",
    "                                   n_blocks=n_blocks,\n",
    "                                   n_time_in=n_time_in,\n",
    "                                   n_time_out=n_time_out,\n",
    "                                   n_x=n_x,\n",
    "                                   n_x_hidden=n_x_hidden,\n",
    "                                   n_s=n_s,\n",
    "                                   n_s_hidden=n_s_hidden,\n",
    "                                   n_layers=n_layers,\n",
    "                                   n_theta_hidden=n_theta_hidden,\n",
    "                                   batch_normalization=batch_normalization,\n",
    "                                   dropout_prob_theta=dropout_prob_theta,\n",
    "                                   activation=activation,\n",
    "                                   shared_weights=shared_weights,\n",
    "                                   n_polynomials=n_polynomials, \n",
    "                                   n_harmonics=n_harmonics,\n",
    "                                   initialization=initialization)\n",
    "        self.blocks = t.nn.ModuleList(blocks)\n",
    "\n",
    "    def create_stack(self, stack_types, n_blocks, \n",
    "                     n_time_in, n_time_out, \n",
    "                     n_x, n_x_hidden, n_s, n_s_hidden, \n",
    "                     n_layers, n_theta_hidden, batch_normalization, dropout_prob_theta, \n",
    "                     activation, shared_weights,\n",
    "                     n_polynomials, n_harmonics, initialization):                     \n",
    "\n",
    "        block_list = []\n",
    "        for i in range(len(stack_types)):\n",
    "            #print(f'| --  Stack {stack_types[i]} (#{i})')\n",
    "            for block_id in range(n_blocks[i]):\n",
    "                \n",
    "                # Batch norm only on first block\n",
    "                if (len(block_list)==0) and (batch_normalization):\n",
    "                    batch_normalization_block = True\n",
    "                else:\n",
    "                    batch_normalization_block = False\n",
    "\n",
    "                # Shared weights\n",
    "                if shared_weights and block_id>0:\n",
    "                    nbeats_block = block_list[-1]\n",
    "                else:\n",
    "                    if stack_types[i] == 'seasonality':\n",
    "                        n_theta = 4 * int(np.ceil(n_harmonics / 2 * n_time_out) - (n_harmonics - 1))\n",
    "                        basis = SeasonalityBasis(harmonics=n_harmonics,\n",
    "                                                 backcast_size=n_time_in,\n",
    "                                                 forecast_size=n_time_out)\n",
    "\n",
    "                    elif stack_types[i] == 'trend':\n",
    "                        n_theta = 2 * (n_polynomials + 1)\n",
    "                        basis = TrendBasis(degree_of_polynomial=n_polynomials,\n",
    "                                           backcast_size=n_time_in,\n",
    "                                           forecast_size=n_time_out)\n",
    "\n",
    "                    elif stack_types[i] == 'identity':\n",
    "                        n_theta = n_time_in + n_time_out\n",
    "                        basis = IdentityBasis(backcast_size=n_time_in,\n",
    "                                              forecast_size=n_time_out)                        \n",
    "\n",
    "                    elif stack_types[i] == 'exogenous':\n",
    "                        n_theta = 2 * n_x\n",
    "                        basis = ExogenousBasisInterpretable()\n",
    "\n",
    "                    elif stack_types[i] == 'exogenous_tcn':\n",
    "                        n_theta = 2 * n_x_hidden\n",
    "                        basis = ExogenousBasisTCN(n_x_hidden, n_x)\n",
    "\n",
    "                    elif stack_types[i] == 'exogenous_wavenet':\n",
    "                        n_theta = 2 * n_x_hidden\n",
    "                        basis = ExogenousBasisWavenet(n_x_hidden, n_x)\n",
    "\n",
    "                    else:\n",
    "                        assert 1<0, f'Block type not found!'\n",
    "\n",
    "                    nbeats_block = _NBEATSBlock(n_time_in=n_time_in,\n",
    "                                                n_time_out=n_time_out,\n",
    "                                                n_x=n_x,\n",
    "                                                n_s=n_s,\n",
    "                                                n_s_hidden=n_s_hidden,\n",
    "                                                n_theta=n_theta,\n",
    "                                                n_theta_hidden=n_theta_hidden[i],\n",
    "                                                basis=basis,\n",
    "                                                n_layers=n_layers[i],\n",
    "                                                batch_normalization=batch_normalization_block,\n",
    "                                                dropout_prob=dropout_prob_theta,\n",
    "                                                activation=activation)\n",
    "\n",
    "                # Select type of evaluation and apply it to all layers of block\n",
    "                init_function = partial(init_weights, initialization=initialization)                                             \n",
    "                nbeats_block.layers.apply(init_function)\n",
    "                #print(f'     | -- {nbeats_block}')\n",
    "                block_list.append(nbeats_block)\n",
    "        return block_list\n",
    "\n",
    "    def forward(self, S: t.Tensor, Y: t.Tensor, X: t.Tensor, \n",
    "                insample_mask: t.Tensor, outsample_mask: t.Tensor,\n",
    "                return_decomposition: bool=False):\n",
    "        \n",
    "        # insample\n",
    "        insample_y    = Y[:, :-self.n_time_out]\n",
    "        insample_x_t  = X[:, :, :-self.n_time_out]\n",
    "        insample_mask = insample_mask[:, :-self.n_time_out]\n",
    "        \n",
    "        # outsample\n",
    "        outsample_y   = Y[:, -self.n_time_out:]\n",
    "        outsample_x_t = X[:, :, -self.n_time_out:]\n",
    "        outsample_mask = outsample_mask[:, -self.n_time_out:]\n",
    "\n",
    "        if return_decomposition:\n",
    "            forecast, block_forecasts = self.forecast_decomposition(insample_y=insample_y, \n",
    "                                                                    insample_x_t=insample_x_t, \n",
    "                                                                    insample_mask=insample_mask,\n",
    "                                                                    outsample_x_t=outsample_x_t,\n",
    "                                                                    x_s=S)\n",
    "            return outsample_y, forecast, block_forecasts, outsample_mask\n",
    "        \n",
    "        else:\n",
    "            forecast = self.forecast(insample_y=insample_y,\n",
    "                                     insample_x_t=insample_x_t, \n",
    "                                     insample_mask=insample_mask,\n",
    "                                     outsample_x_t=outsample_x_t,\n",
    "                                     x_s=S)\n",
    "            return outsample_y, forecast, outsample_mask\n",
    "\n",
    "    def forecast(self, insample_y: t.Tensor, insample_x_t: t.Tensor, insample_mask: t.Tensor,\n",
    "                 outsample_x_t: t.Tensor, x_s: t.Tensor):\n",
    "\n",
    "        residuals = insample_y.flip(dims=(-1,))\n",
    "        insample_x_t = insample_x_t.flip(dims=(-1,))\n",
    "        insample_mask = insample_mask.flip(dims=(-1,))\n",
    "\n",
    "        forecast = insample_y[:, -1:] # Level with Naive1\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            backcast, block_forecast = block(insample_y=residuals, insample_x_t=insample_x_t,\n",
    "                                             outsample_x_t=outsample_x_t, x_s=x_s)\n",
    "            residuals = (residuals - backcast) * insample_mask\n",
    "            forecast = forecast + block_forecast\n",
    "\n",
    "        return forecast\n",
    "\n",
    "    def forecast_decomposition(self, insample_y: t.Tensor, insample_x_t: t.Tensor, insample_mask: t.Tensor,\n",
    "                               outsample_x_t: t.Tensor, x_s: t.Tensor):\n",
    "\n",
    "        residuals = insample_y.flip(dims=(-1,))\n",
    "        insample_x_t = insample_x_t.flip(dims=(-1,))\n",
    "        insample_mask = insample_mask.flip(dims=(-1,))\n",
    "        \n",
    "        n_batch, n_channels, n_t = outsample_x_t.size(0), outsample_x_t.size(1), outsample_x_t.size(2)\n",
    "        \n",
    "        level = insample_y[:, -1:] # Level with Naive1\n",
    "        block_forecasts = [ level.repeat(1, n_t) ]\n",
    "                \n",
    "        forecast = level\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            backcast, block_forecast = block(insample_y=residuals, insample_x_t=insample_x_t,\n",
    "                                             outsample_x_t=outsample_x_t, x_s=x_s)\n",
    "            residuals = (residuals - backcast) * insample_mask\n",
    "            forecast = forecast + block_forecast\n",
    "            block_forecasts.append(block_forecast)\n",
    "            \n",
    "        # (n_batch, n_blocks, n_t)\n",
    "        block_forecasts = t.stack(block_forecasts)\n",
    "        block_forecasts = block_forecasts.permute(1,0,2)\n",
    "\n",
    "        return forecast, block_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = _NBEATS(n_time_in=168,\n",
    "                n_time_out=24,\n",
    "                n_s=1,\n",
    "                n_x=10,\n",
    "                n_s_hidden=100,\n",
    "                n_x_hidden=30,\n",
    "                n_polynomials=2,\n",
    "                n_harmonics=4,\n",
    "                stack_types=['trend', 'seasonality', 'exogenous_wavenet'],\n",
    "                n_blocks=[1, 1, 1],\n",
    "                n_layers=[2, 2, 2],\n",
    "                n_theta_hidden=3 * [[128, 128]],\n",
    "                dropout_prob_theta=0,\n",
    "                activation='SELU',\n",
    "                initialization='lecun_normal',\n",
    "                batch_normalization=True,\n",
    "                shared_weights=True)\n",
    "\n",
    "# inputs: S, Y, X, insample_mask\n",
    "# S.shape (n_batch,n_s)\n",
    "# Y.shape (n_batch,n_time_in+n_time_out) \n",
    "# X.shape (n_batch,n_x,n_time_in+n_time_out)\n",
    "# insample_mask.shape (n_batch,n_time_in+n_time_out)\n",
    "# summary(model, input_size=[(256, 1), (256, 168+24), (256, 10, 168+24), (256, 168+24)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch import optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from nixtlats.losses.pytorch import (\n",
    "    MAPELoss, MASELoss, SMAPELoss, \n",
    "    MSELoss, MAELoss, PinballLoss\n",
    ")\n",
    "from nixtlats.losses.numpy import (\n",
    "    mae, mse, mape, \n",
    "    smape, rmse, pinball_loss\n",
    ")\n",
    "\n",
    "from nixtlats.data.tsdataset import WindowsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBEATS(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 n_time_in,\n",
    "                 n_time_out,\n",
    "                 n_x,\n",
    "                 n_x_hidden,\n",
    "                 n_s,\n",
    "                 n_s_hidden,\n",
    "                 shared_weights,\n",
    "                 activation,\n",
    "                 initialization,\n",
    "                 stack_types,\n",
    "                 n_blocks,\n",
    "                 n_layers,\n",
    "                 n_harmonics,\n",
    "                 n_polynomials,\n",
    "                 n_theta_hidden,\n",
    "                 batch_normalization,\n",
    "                 dropout_prob_theta,\n",
    "                 learning_rate,\n",
    "                 lr_decay,\n",
    "                 lr_decay_step_size,\n",
    "                 weight_decay,\n",
    "                 loss_train,\n",
    "                 loss_hypar,\n",
    "                 loss_valid,\n",
    "                 frequency,\n",
    "                 random_seed,\n",
    "                 seasonality):\n",
    "        super(NBEATS, self).__init__()\n",
    "        \"\"\"\n",
    "        N-BEATS model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        # TODO: Fix parameters' documentation.\n",
    "        # TODO: Remove useless parameters (dropout_prob_exogenous).\n",
    "        n_time_in: int\n",
    "            Multiplier to get insample size.\n",
    "            Insample size = n_time_in * output_size\n",
    "        n_time_out: int\n",
    "            Forecast horizon.\n",
    "        shared_weights: bool\n",
    "            If True, repeats first block.\n",
    "        activation: str\n",
    "            Activation function.\n",
    "            An item from ['relu', 'softplus', 'tanh', 'selu', 'lrelu', 'prelu', 'sigmoid'].\n",
    "        initialization: str\n",
    "            Initialization function.\n",
    "            An item from ['orthogonal', 'he_uniform', 'glorot_uniform', 'glorot_normal', 'lecun_normal'].\n",
    "        stack_types: List[str]\n",
    "            List of stack types.\n",
    "            Subset from ['seasonality', 'trend', 'identity', 'exogenous', 'exogenous_tcn', 'exogenous_wavenet'].\n",
    "        n_blocks: List[int]\n",
    "            Number of blocks for each stack type.\n",
    "            Note that len(n_blocks) = len(stack_types).\n",
    "        n_layers: List[int]\n",
    "            Number of layers for each stack type.\n",
    "            Note that len(n_layers) = len(stack_types).\n",
    "        n_hidden: List[List[int]]\n",
    "            Structure of hidden layers for each stack type.\n",
    "            Each internal list should contain the number of units of each hidden layer.\n",
    "            Note that len(n_hidden) = len(stack_types).\n",
    "        n_harmonics: List[int]\n",
    "            Number of harmonic terms for each stack type.\n",
    "            Note that len(n_harmonics) = len(stack_types).\n",
    "        n_polynomials: List[int]\n",
    "            Number of polynomial terms for each stack type.\n",
    "            Note that len(n_polynomials) = len(stack_types).\n",
    "        exogenous_n_channels:\n",
    "            Exogenous channels for non-interpretable exogenous basis.\n",
    "        batch_normalization: bool\n",
    "            Whether perform batch normalization. \n",
    "        dropout_prob_theta: float\n",
    "            Float between (0, 1).\n",
    "            Dropout for Nbeats basis.\n",
    "        dropout_prob_exogenous: float\n",
    "            Float between (0, 1).\n",
    "            Dropout for exogenous basis.\n",
    "        x_s_n_hidden: int\n",
    "            Number of encoded static features to calculate.\n",
    "        learning_rate: float\n",
    "            Learning rate between (0, 1).\n",
    "        lr_decay: float\n",
    "            Decreasing multiplier for the learning rate.\n",
    "        lr_decay_step_size: int\n",
    "            Steps between each lerning rate decay.\n",
    "        weight_decay: float\n",
    "            L2 penalty for optimizer.\n",
    "        loss_train: str\n",
    "            Loss to optimize.\n",
    "            An item from ['MAPE', 'MASE', 'SMAPE', 'MSE', 'MAE', 'PINBALL', 'PINBALL2'].\n",
    "        loss_hypar:\n",
    "            Hyperparameter for chosen loss.\n",
    "        loss_valid:\n",
    "            Validation loss.\n",
    "            An item from ['MAPE', 'MASE', 'SMAPE', 'RMSE', 'MAE', 'PINBALL'].\n",
    "        frequency: str\n",
    "            Time series frequency.\n",
    "        random_seed: int\n",
    "            random_seed for pseudo random pytorch initializer and\n",
    "            numpy random generator.\n",
    "        seasonality: int\n",
    "            Time series seasonality.\n",
    "            Usually 7 for daily data, 12 for monthly data and 4 for weekly data.\n",
    "        \"\"\"\n",
    "\n",
    "        if activation == 'SELU': initialization = 'lecun_normal'\n",
    "\n",
    "        #------------------------ Model Attributes ------------------------#\n",
    "        # Architecture parameters\n",
    "        self.n_time_in = n_time_in\n",
    "        self.n_time_out = n_time_out\n",
    "        self.n_x = n_x\n",
    "        self.n_x_hidden = n_x_hidden\n",
    "        self.n_s = n_s\n",
    "        self.n_s_hidden = n_s_hidden\n",
    "        self.shared_weights = shared_weights\n",
    "        self.activation = activation\n",
    "        self.initialization = initialization\n",
    "        self.stack_types = stack_types\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.n_harmonics = n_harmonics\n",
    "        self.n_polynomials = n_polynomials\n",
    "        self.n_theta_hidden = n_theta_hidden\n",
    "\n",
    "        # Loss functions\n",
    "        self.loss_train = loss_train\n",
    "        self.loss_hypar = loss_hypar\n",
    "        self.loss_valid = loss_valid\n",
    "        self.loss_fn_train = LossFunction(loss_train, \n",
    "                                          seasonality=self.loss_hypar)\n",
    "        self.loss_fn_valid = LossFunction(loss_valid,\n",
    "                                          seasonality=self.loss_hypar)\n",
    "        \n",
    "        # Regularization and optimization parameters\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout_prob_theta = dropout_prob_theta        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_decay = lr_decay\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lr_decay_step_size = lr_decay_step_size\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        # Data parameters\n",
    "        self.frequency = frequency\n",
    "        self.seasonality = seasonality\n",
    "        self.return_decomposition = False\n",
    "\n",
    "        self.model = _NBEATS(n_time_in=self.n_time_in,\n",
    "                             n_time_out=self.n_time_out,\n",
    "                             n_s=self.n_s,\n",
    "                             n_x=self.n_x,\n",
    "                             n_s_hidden=self.n_s_hidden,\n",
    "                             n_x_hidden=self.n_x_hidden,\n",
    "                             n_polynomials=self.n_polynomials,\n",
    "                             n_harmonics=self.n_harmonics,\n",
    "                             stack_types=self.stack_types,\n",
    "                             n_blocks=self.n_blocks,\n",
    "                             n_layers=self.n_layers,\n",
    "                             n_theta_hidden=self.n_theta_hidden,\n",
    "                             dropout_prob_theta=self.dropout_prob_theta,\n",
    "                             activation=self.activation,\n",
    "                             initialization=self.initialization,\n",
    "                             batch_normalization=self.batch_normalization,\n",
    "                             shared_weights=self.shared_weights)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        sample_mask = batch['sample_mask']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           outsample_mask=sample_mask,\n",
    "                                                           return_decomposition=False)\n",
    "\n",
    "        loss = self.loss_fn_train(y=outsample_y,\n",
    "                                  y_hat=forecast,\n",
    "                                  mask=outsample_mask,\n",
    "                                  y_insample=Y)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, idx):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        sample_mask = batch['sample_mask']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           outsample_mask=sample_mask,\n",
    "                                                           return_decomposition=False)\n",
    "\n",
    "        loss = self.loss_fn_valid(y=outsample_y,\n",
    "                                  y_hat=forecast,\n",
    "                                  mask=outsample_mask,\n",
    "                                  y_insample=Y)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        t.manual_seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        random.seed(self.random_seed) #TODO: interaccion rara con window_sampling de validacion\n",
    "\n",
    "    def forward(self, batch):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        sample_mask = batch['sample_mask']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        if self.return_decomposition:\n",
    "            outsample_y, forecast, block_forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                                     insample_mask=available_mask,\n",
    "                                                                     outsample_mask=sample_mask,\n",
    "                                                                     return_decomposition=True)\n",
    "            return outsample_y, forecast, block_forecast, outsample_mask\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           outsample_mask=sample_mask,\n",
    "                                                           return_decomposition=False)\n",
    "        return outsample_y, forecast, outsample_mask\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=self.learning_rate, \n",
    "                               weight_decay=self.weight_decay)\n",
    "        \n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                 step_size=self.lr_decay_step_size, \n",
    "                                                 gamma=self.lr_decay)\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': lr_scheduler}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS Usage Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "from nixtlats.data.datasets.epf import EPF#, EPFInfo\n",
    "from nixtlats.data.tsloader import TimeSeriesLoader\n",
    "\n",
    "import pylab as plt\n",
    "from pylab import rcParams\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "FONTSIZE = 19\n",
    "\n",
    "# Load and plot data\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='./data', groups=['NP'])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "plt.plot(Y_df.ds, Y_df.y.values, color='#628793', linewidth=0.4)\n",
    "plt.ylabel('Price [EUR/MWh]', fontsize=19)\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "# plt.savefig('./results/NP.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Model and Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "model                                                      nbeats\n",
      "mode                                                       simple\n",
      "activation                                                   SELU\n",
      "n_time_in                                                     168\n",
      "n_time_out                                                    168\n",
      "n_x_hidden                                                      8\n",
      "n_s_hidden                                                      0\n",
      "stack_types               [trend, seasonality, exogenous_wavenet]\n",
      "n_blocks                                                [1, 1, 1]\n",
      "n_layers                                                [2, 2, 2]\n",
      "n_hidden                                                      128\n",
      "shared_weights                                              False\n",
      "n_harmonics                                                     2\n",
      "n_polynomials                                                   4\n",
      "initialization                                       lecun_normal\n",
      "learning_rate                                              0.0005\n",
      "batch_size                                                    256\n",
      "lr_decay                                                      0.5\n",
      "lr_decay_step_size                                              2\n",
      "max_epochs                                                      1\n",
      "max_steps                                                      20\n",
      "early_stop_patience                                            20\n",
      "eval_freq                                                     500\n",
      "batch_normalization                                         False\n",
      "dropout_prob_theta                                              0\n",
      "dropout_prob_exogenous                                          0\n",
      "l1_theta                                                        0\n",
      "weight_decay                                                6e-05\n",
      "loss_train                                                    MAE\n",
      "loss_hypar                                                    0.5\n",
      "loss_valid                                                    MAE\n",
      "random_seed                                                     1\n",
      "len_sample_chunks                                            None\n",
      "idx_to_sample_freq                                              1\n",
      "val_idx_to_sample_freq                                        168\n",
      "n_val_weeks                                                    52\n",
      "window_sampling_limit                                      500000\n",
      "normalizer_y                                                 None\n",
      "normalizer_x                                               median\n",
      "complete_inputs                                             False\n",
      "frequency                                                       H\n",
      "seasonality                                                    24\n",
      "dtype: object\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "mc = {}\n",
    "mc['model'] = 'nbeats'\n",
    "mc['mode'] = 'simple'\n",
    "mc['activation'] = 'SELU'\n",
    "\n",
    "mc['n_time_in'] = 24*7\n",
    "mc['n_time_out'] = 24*7\n",
    "mc['n_x_hidden'] = 8\n",
    "mc['n_s_hidden'] = 0\n",
    "\n",
    "# mc['input_size_multiplier'] = 7\n",
    "# mc['output_size'] = 24\n",
    "\n",
    "mc['stack_types'] = ['trend', 'seasonality', 'exogenous_wavenet']\n",
    "mc['n_blocks'] = [1, 1, 1]\n",
    "mc['n_layers'] = [2, 2, 2]\n",
    "# mc['stack_types'] = ['trend', 'seasonality']\n",
    "# mc['n_blocks'] = [1, 1]\n",
    "# mc['n_layers'] = [2, 2]\n",
    "\n",
    "mc['n_hidden'] = 128\n",
    "mc['shared_weights'] = False\n",
    "mc['n_harmonics'] = 4\n",
    "mc['n_polynomials'] = 2\n",
    "\n",
    "# Optimization and regularization parameters\n",
    "mc['initialization'] = 'lecun_normal'\n",
    "mc['learning_rate'] = 0.0007\n",
    "mc['batch_size'] = 128\n",
    "mc['lr_decay'] = 0.5\n",
    "mc['lr_decay_step_size'] = 2\n",
    "mc['max_epochs'] = 1#_000\n",
    "mc['max_steps'] = 20#_000\n",
    "mc['early_stop_patience'] = 20\n",
    "mc['eval_freq'] = 500\n",
    "mc['batch_normalization'] = False\n",
    "mc['dropout_prob_theta'] = 0.51\n",
    "mc['dropout_prob_exogenous'] = 0.44\n",
    "mc['l1_theta'] = 0\n",
    "mc['weight_decay'] = 0\n",
    "mc['loss_train'] = 'MAE'\n",
    "mc['loss_hypar'] = 0.5\n",
    "mc['loss_valid'] = mc['loss_train']\n",
    "mc['random_seed'] = 1\n",
    "\n",
    "# Data Parameters\n",
    "mc['len_sample_chunks'] = None\n",
    "mc['idx_to_sample_freq'] = 1\n",
    "mc['val_idx_to_sample_freq'] = 24 * 7\n",
    "mc['n_val_weeks'] = 52\n",
    "mc['window_sampling_limit'] = 500_000\n",
    "mc['normalizer_y'] = None\n",
    "mc['normalizer_x'] = 'median'\n",
    "mc['complete_inputs'] = False\n",
    "mc['frequency'] = 'H'\n",
    "mc['seasonality'] = 24\n",
    "\n",
    "# # Within decomposition\n",
    "mc['learning_rate'] = 0.0005\n",
    "mc['batch_size'] = 256\n",
    "mc['weight_decay'] = 0.00006\n",
    "mc['n_harmonics'] = 2\n",
    "mc['n_polynomials'] = 4\n",
    "mc['dropout_prob_theta'] = 0\n",
    "mc['dropout_prob_exogenous'] = 0\n",
    "\n",
    "print(65*'=')\n",
    "print(pd.Series(mc))\n",
    "print(65*'=')\n",
    "\n",
    "mc['n_theta_hidden'] = len(mc['stack_types']) * [ [int(mc['n_hidden']), int(mc['n_hidden'])] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Loaders and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2016-03-08 2018-12-24 23:00:00\n",
      "          1           2013-01-01 2016-03-07 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=53.21, \t27888 time stamps \n",
      "Outsample percentage=46.79, \t24528 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2018-12-24 23:00:00\n",
      "          1           2016-03-08 2016-12-26 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=13.46, \t7056 time stamps \n",
      "Outsample percentage=86.54, \t45360 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2016-12-26 23:00:00\n",
      "          1           2016-12-27 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=33.33, \t17472 time stamps \n",
      "Outsample percentage=66.67, \t34944 time stamps \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nixtlats.experiments.utils import create_datasets\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, scaler_y = create_datasets(mc=mc,\n",
    "                                                                     S_df=S_df, Y_df=Y_df, X_df=X_df,\n",
    "                                                                     f_cols=['Exogenous1', 'Exogenous2'],\n",
    "                                                                     ds_in_val=294*24,\n",
    "                                                                     ds_in_test=728*24,\n",
    "                                                                     n_uids=None, n_val_windows=None,freq=None, \n",
    "                                                                     is_val_random=False)\n",
    "\n",
    "train_loader = TimeSeriesLoader(dataset=train_dataset,\n",
    "                                batch_size=int(mc['batch_size']),\n",
    "                                #num_workers=int(min(multiprocessing.cpu_count(), 3)),\n",
    "                                shuffle=True)\n",
    "\n",
    "val_loader = TimeSeriesLoader(dataset=val_dataset,\n",
    "                              batch_size=int(mc['batch_size']),\n",
    "                              #num_workers=int(min(multiprocessing.cpu_count(), 3)),\n",
    "                              shuffle=False)\n",
    "\n",
    "test_loader = TimeSeriesLoader(dataset=test_dataset,\n",
    "                               batch_size=int(mc['batch_size']),\n",
    "                               #num_workers=int(min(multiprocessing.cpu_count(), 3)),\n",
    "                               shuffle=False)\n",
    "\n",
    "mc['n_x'], mc['n_s'] = train_dataset.get_n_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBEATS(n_time_in=int(mc['n_time_in']),\n",
    "               n_time_out=int(mc['n_time_out']),\n",
    "               n_x=mc['n_x'],\n",
    "               n_s=mc['n_s'],\n",
    "               n_s_hidden=int(mc['n_s_hidden']),\n",
    "               n_x_hidden=int(mc['n_x_hidden']),\n",
    "               shared_weights=mc['shared_weights'],\n",
    "               initialization=mc['initialization'],\n",
    "               activation=mc['activation'],\n",
    "               stack_types=mc['stack_types'],\n",
    "               n_blocks=mc['n_blocks'],\n",
    "               n_layers=mc['n_layers'],\n",
    "               n_theta_hidden=mc['n_theta_hidden'],\n",
    "               n_harmonics=int(mc['n_harmonics']),\n",
    "               n_polynomials=int(mc['n_polynomials']),\n",
    "               batch_normalization = mc['batch_normalization'],\n",
    "               dropout_prob_theta=mc['dropout_prob_theta'],\n",
    "               learning_rate=float(mc['learning_rate']),\n",
    "               lr_decay=float(mc['lr_decay']),\n",
    "               lr_decay_step_size=float(mc['lr_decay_step_size']),\n",
    "               weight_decay=mc['weight_decay'],\n",
    "               loss_train=mc['loss_train'],\n",
    "               loss_hypar=float(mc['loss_hypar']),\n",
    "               loss_valid=mc['loss_valid'],\n",
    "               frequency=mc['frequency'],\n",
    "               seasonality=int(mc['seasonality']),\n",
    "               random_seed=int(mc['random_seed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:597: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  \"GPU available but not used. Set the gpus flag in your trainer\"\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | _NBEATS | 1.6 M \n",
      "----------------------------------\n",
      "1.5 M     Trainable params\n",
      "113 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.436     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9118f3b66cb84307b1e79bc1745d6eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0777009ed9441b2bb937a53d55e80b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b1686a18744855b855986d1df1208f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: LightningDeprecationWarning: Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2 and will be removed in v1.4. Please, create your own `mc = ModelCheckpoint(monitor='your_monitor')` and use it as `Trainer(callbacks=[mc])`.\n",
      "  \"Relying on `self.log('val_loss', ...)` to set the ModelCheckpoint monitor is deprecated in v1.2\"\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", \n",
    "                               min_delta=1e-4, \n",
    "                               patience=mc['early_stop_patience'],\n",
    "                               verbose=False,\n",
    "                               mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=mc['max_epochs'], \n",
    "                     max_steps=mc['max_steps'],\n",
    "                     gradient_clip_val=1.0,\n",
    "                     progress_bar_refresh_rate=10, \n",
    "                     log_every_n_steps=500, \n",
    "                     check_val_every_n_epoch=1,\n",
    "                     callbacks=[early_stopping])\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0493c9bfed3446f58c26c89f8c308626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Predicting', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outputs[0][0].shape torch.Size([42, 168])\n",
      "outputs[0][1].shape torch.Size([42, 168])\n",
      "outputs[0][2].shape torch.Size([42, 4, 168])\n"
     ]
    }
   ],
   "source": [
    "model.return_decomposition = True\n",
    "outputs = trainer.predict(model, val_loader)\n",
    "\n",
    "print(\"outputs[0][0].shape\", outputs[0][0].shape)\n",
    "print(\"outputs[0][1].shape\", outputs[0][1].shape)\n",
    "print(\"outputs[0][2].shape\", outputs[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
